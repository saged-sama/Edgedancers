{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"SKNahin/bengali-transliteration-data\")\n\ntrain_test_split = dataset['train'].train_test_split(test_size=0.2)\ntrain_dataset = train_test_split['train']\nvalidation_dataset = train_test_split['test']","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:47:27.771820Z","iopub.execute_input":"2024-12-21T14:47:27.772867Z","iopub.status.idle":"2024-12-21T14:47:30.791339Z","shell.execute_reply.started":"2024-12-21T14:47:27.772820Z","shell.execute_reply":"2024-12-21T14:47:30.790270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n\ndef tokenize_function(examples):\n    inputs = examples['rm']\n    targets = examples['bn']\n    model_inputs = tokenizer(inputs, text_target=targets, truncation=True)\n    return model_inputs\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\nvalidation_dataset = validation_dataset.map(tokenize_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:47:30.792337Z","iopub.execute_input":"2024-12-21T14:47:30.792874Z","iopub.status.idle":"2024-12-21T14:47:39.126500Z","shell.execute_reply.started":"2024-12-21T14:47:30.792839Z","shell.execute_reply":"2024-12-21T14:47:39.125506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/banglat5\")\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_total_limit=3,\n    predict_with_generate=True\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    tokenizer=tokenizer\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:47:39.127453Z","iopub.execute_input":"2024-12-21T14:47:39.127670Z","iopub.status.idle":"2024-12-21T15:01:16.363845Z","shell.execute_reply.started":"2024-12-21T14:47:39.127651Z","shell.execute_reply":"2024-12-21T15:01:16.362399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}